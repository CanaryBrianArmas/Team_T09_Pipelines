{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Pipeline for Income Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script implements a machine learning pipeline to classify income levels based on various features.\n",
    "\n",
    "The pipeline includes data preprocessing, feature transformation, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure necessary directories exist\n",
    "os.makedirs(\"./src/models\", exist_ok=True)\n",
    "os.makedirs(\"./src/result_notebooks\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv(\"./src/data/train.csv\")\n",
    "df_test = pd.read_csv(\"./src/data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Training Data Info:\\n\")\n",
    "df_train.info()\n",
    "print(\"\\nTest Data Info:\\n\")\n",
    "df_test.info()\n",
    "\n",
    "# Display first few rows of the dataset\n",
    "print(\"\\nFirst few rows of training data:\\n\")\n",
    "print(df_train.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\\n\")\n",
    "print(df_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values in Training Data:\\n\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "# Target variable analysis\n",
    "print(\"\\nTarget Variable Distribution (INCOME):\\n\")\n",
    "print(df_train[\"INCOME\"].value_counts())\n",
    "\n",
    "# Plot the distribution of the target variable\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df_train, x=\"INCOME\", palette=\"viridis\")\n",
    "plt.title(\"Distribution of Target Variable (INCOME)\")\n",
    "plt.xlabel(\"Income Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\"\"\"\n",
    "### Data Preprocessing\n",
    "\n",
    "The dataset contains both numerical and categorical features. We need to:\n",
    "1. Handle missing values.\n",
    "2. Encode categorical variables using OneHotEncoder.\n",
    "3. Scale numerical features using StandardScaler.\n",
    "\"\"\"\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df_train.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = df_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_cols.remove(\"INCOME\")  # Remove target variable from features\n",
    "\n",
    "# Define transformers for preprocessing\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine transformers into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\"\"\"\n",
    "### Model Training\n",
    "\n",
    "We will train three different models:\n",
    "1. RandomForestClassifier\n",
    "2. GradientBoostingClassifier\n",
    "3. LogisticRegression\n",
    "\n",
    "The best-performing model will be selected based on cross-validation scores.\n",
    "\"\"\"\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Train models and evaluate performance\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    scores = cross_val_score(pipeline, df_train.drop(columns=['INCOME']), df_train['INCOME'], cv=5, scoring='accuracy')\n",
    "    print(f\"{name}: Mean Accuracy = {scores.mean():.4f} Â± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_model = (name, model)\n",
    "\n",
    "print(f\"\\nBest Model: {best_model[0]} with Accuracy = {best_score:.4f}\")\n",
    "\n",
    "# Hyperparameter tuning for the best model\n",
    "\"\"\"\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "We will use GridSearchCV to find the best hyperparameters for the selected model.\n",
    "\"\"\"\n",
    "\n",
    "param_grid = {\n",
    "    \"Random Forest\": {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [10, 20, None],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 5, 10]\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10],\n",
    "        'classifier__solver': ['lbfgs', 'liblinear']\n",
    "    }\n",
    "}\n",
    "\n",
    "best_model_name, best_model_instance = best_model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', best_model_instance)])\n",
    "grid_search = GridSearchCV(pipeline, param_grid[best_model_name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(df_train.drop(columns=['INCOME']), df_train['INCOME'])\n",
    "\n",
    "# Display best parameters and best score\n",
    "print(f\"Best parameters for {best_model_name}: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation on Test Data\n",
    "\"\"\"\n",
    "### Model Evaluation\n",
    "\n",
    "Now, we evaluate the best model on the test dataset and generate key performance metrics.\n",
    "\"\"\"\n",
    "\n",
    "# Make predictions\n",
    "y_test = df_test[\"INCOME\"]\n",
    "X_test = df_test.drop(columns=[\"INCOME\"])\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Print accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "\"\"\"\n",
    "### Save the Best Model\n",
    "\n",
    "We save the best trained model using joblib for future use.\n",
    "\"\"\"\n",
    "\n",
    "model_path = \"./src/models/best_model.joblib\"\n",
    "joblib.dump(grid_search.best_estimator_, model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
